{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4158\n",
      "4158\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from azure.storage.queue import QueueService\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format:\n",
    "\n",
    "```\n",
    "{\n",
    "\"info\": \n",
    "    {\n",
    "    \"station\": 1244, \n",
    "    \"type\": \"TAKE\", \n",
    "    \"user\": \"charles.yu\", \n",
    "    \"time\": 1555776040\n",
    "    }, \n",
    "\"type\": \"TAKE\" // \"RETURN\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummy_task():\n",
    "    task_str = '{\"info\": {\"station\": 4177, \"type\": \"RETURN\", \"user\": \"charles.yu\", \"time\": 1555776040}, \"type\": \"RETURN\"}'\n",
    "    queue_service.put_message(QUEUE_NAME, task_str)\n",
    "\n",
    "for _ in range(32):\n",
    "    add_dummy_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event:\n",
    "    def __init__(self, event_type, station, time):\n",
    "        self.event_type = event_type\n",
    "        self.station = station\n",
    "        self.time = time\n",
    "\n",
    "def parse_result(message):\n",
    "    msg = json.loads(message)\n",
    "    info = msg['info']\n",
    "    return Event(info['type'], info['station'], info['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_KEY = os.getenv('ACCOUNT_KEY')\n",
    "ACCOUNT_NAME = os.getenv('ACCOUNT_NAME')\n",
    "MAX_MESSAGE_LIMIT = 32\n",
    "QUEUE_NAME = 'batchqueue'\n",
    "\n",
    "infile = open('station_cols','rb')\n",
    "columns = pickle.load(infile)\n",
    "infile = open('model','rb')\n",
    "model = pickle.load(infile)\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "queue_service = QueueService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "def get_queue_data():\n",
    "    metadata = queue_service.get_queue_metadata(QUEUE_NAME)\n",
    "    count = metadata.approximate_message_count\n",
    "    messages_read = 0\n",
    "    \n",
    "    while messages_read < count:\n",
    "        num_messages = count - messages_read if count - messages_read < 32 else 32\n",
    "        if DEBUG:\n",
    "            messages = queue_service.peek_messages(QUEUE_NAME, num_messages=num_messages)\n",
    "        else:\n",
    "            messages = queue_service.get_messages(QUEUE_NAME, num_messages=num_messages)\n",
    "        deltas = { station: 0 for station in columns }\n",
    "        for message in messages:\n",
    "            event = parse_result(message.content)\n",
    "            if event.event_type == 'TAKE':\n",
    "                deltas[event.station] -= 1\n",
    "            else:\n",
    "                deltas[event.station] += 1\n",
    "            if not DEBUG:\n",
    "                queue_service.delete_message(QUEUE_NAME, message.id, message.pop_receipt)\n",
    "        messages_read += len(messages)\n",
    "    last_msg = parse_result(messages[-1].content)\n",
    "    deltas['time'] = last_msg.time\n",
    "    deltas = { k: [v] for k, v in deltas.items() }\n",
    "    df = pd.DataFrame.from_dict(deltas)\n",
    "    return model.predict(df)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4158\n"
     ]
    }
   ],
   "source": [
    "next_call = time.time()\n",
    "PULL_INTERVAL = 600 # in seconds\n",
    "\n",
    "def run_loop():\n",
    "    global next_call\n",
    "    print(get_queue_data())\n",
    "    next_call = next_call + PULL_INTERVAL\n",
    "    threading.Timer(next_call - time.time(), run_loop).start()\n",
    "\n",
    "run_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
